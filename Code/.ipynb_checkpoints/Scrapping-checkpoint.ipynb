{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping Data for different #tag and search words for 3rd and 4th of Oct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Facebook, #Whatsapp, #Instagram, Outage\n",
    "tweets_list1 = []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#facebook since:2021-10-04 until:2021-10-05').get_items()):\n",
    "    tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "facebook = pd.DataFrame(tweets_list1, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list2 = []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('outage since:2021-10-04 until:2021-10-05').get_items()):\n",
    "    tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "outage = pd.DataFrame(tweets_list2, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list3= []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#Whatsapp since:2021-10-04 until:2021-10-05').get_items()):\n",
    "    tweets_list3.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "whatsapp= pd.DataFrame(tweets_list3, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list4= []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#Instagram since:2021-10-04 until:2021-10-05').get_items()):\n",
    "    tweets_list4.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "Instagram= pd.DataFrame(tweets_list4, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whistleblower hashtag and facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list5= []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('facebook since:2021-10-03 until:2021-10-04').get_items()):\n",
    "    tweets_list5.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "whistleblower= pd.DataFrame(tweets_list5, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[facebook, outage, whatsapp, Instagram]\n",
    "data =pd.concat(frames) \n",
    "data.to_csv('..\\Data\\data.csv', index=False)\n",
    "whistleblower.to_csv('..\\Data\\data_whs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping data for 6th Oct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets6 = []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#facebook since:2021-10-06 until:2021-10-07').get_items()):\n",
    "    tweets6.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "facebook6 = pd.DataFrame(tweets6, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets62 = []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('outage since:2021-10-06 until:2021-10-07').get_items()):\n",
    "    tweets62.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "outage6 = pd.DataFrame(tweets62, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets63 = []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#Whatsapp since:2021-10-06 until:2021-10-07').get_items()):\n",
    "    tweets63.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "whatsapp6 = pd.DataFrame(tweets63, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets64 = []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#Instagram since:2021-10-06 until:2021-10-07').get_items()):\n",
    "    tweets64.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "Instagram6 = pd.DataFrame(tweets64, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames6=[facebook6,outage6, whatsapp6, Instagram6]\n",
    "data6 =pd.concat(frames6) \n",
    "data6.to_csv('..\\Data\\data6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_whs= []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('whistleblower since:2021-10-06 until:2021-10-07').get_items()):\n",
    "    tweets_whs.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "whistleblower6= pd.DataFrame(tweets_whs, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
    "whistleblower6.to_csv('..\\Data\\whistleblower6.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping data for 10th Oct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets10 = []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#facebook since:2021-10-10 until:2021-10-11').get_items()):\n",
    "    tweets10.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "facebook10 = pd.DataFrame(tweets10, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets102 = []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('outage since:2021-10-10 until:2021-10-11').get_items()):\n",
    "    tweets102.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "outage10 = pd.DataFrame(tweets102, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets103 = []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#whatsapp since:2021-10-10 until:2021-10-11').get_items()):\n",
    "    tweets103.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "whatsapp10 = pd.DataFrame(tweets103, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets104 = []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#instagram since:2021-10-10 until:2021-10-11').get_items()):\n",
    "    tweets104.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "instagram10 = pd.DataFrame(tweets104, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames10=[facebook10,outage10, whatsapp10, instagram10]\n",
    "data10 =pd.concat(frames10) \n",
    "data10.to_csv('..\\Data\\data10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_whs10= []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('whistleblower since:2021-10-10 until:2021-10-11').get_items()):\n",
    "    tweets_whs10.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "whistleblower10= pd.DataFrame(tweets_whs10, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
    "whistleblower10.to_csv('..\\Data\\whistleblower10.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping 15th Oct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets15 = []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#facebook since:2021-10-15 until:2021-10-16').get_items()):\n",
    "    tweets15.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "facebook15 = pd.DataFrame(tweets15, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets152 = []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#whatsapp since:2021-10-15 until:2021-10-16').get_items()):\n",
    "    tweets152.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "whatsapp15 = pd.DataFrame(tweets152, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets153 = []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#instagram since:2021-10-15 until:2021-10-16').get_items()):\n",
    "    tweets153.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "instagram15 = pd.DataFrame(tweets153, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets154 = []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('outage since:2021-10-15 until:2021-10-16').get_items()):\n",
    "    tweets154.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "outage15 = pd.DataFrame(tweets154, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames15=[facebook15,outage15, whatsapp15, instagram15]\n",
    "data15 =pd.concat(frames15) \n",
    "data15.to_csv('..\\Data\\data15.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_whs15= []\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('whistleblower since:2021-10-15 until:2021-10-16').get_items()):\n",
    "    tweets_whs15.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "whistleblower15= pd.DataFrame(tweets_whs15, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
    "whistleblower15.to_csv('..\\Data\\whistleblower15.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
